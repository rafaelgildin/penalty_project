{"cells":[{"cell_type":"markdown","metadata":{"id":"8GD35KB1XiYF"},"source":["# Code\n","\n","## Conclusions\n","- By increasing the dataset, the model demonstrated that learn without overfitting.\n","  It's proven to see it in the outputs videos.\n","\n","## Next steps\n","- record 60 fps : 10 left\n","- train a new model version and see the results\n","- if not sucessful, get more data\n","\n","## OBS\n","- Video names explained:\n","    - rf: right feet\n","    - lf: left feet\n","\n","- Data split: train (80%), valid (10%), test (10%)\n","    - train(16) : [lf0-11,rf0-3]\n","    - valid(2) : [lf12,rf4]\n","    - test(2) : [lf13,rf5]\n","\n","- Data transformations:\n","    - Get the same amount of no and yes frames for each video, since the first model failed based on the unbalenced data.\n","    - Consider yes when:  \n","        - starts when support foot is fully supported on the floor\n","        - ends before kicking the ball\n","\n","- History of recordings\n","    - 60 fps: lf4 - lf13\n","    - 30 fps: lf0 - lf3, rf0 - rf5"]},{"cell_type":"markdown","metadata":{},"source":["### Dependencies\n","- pip install torch==2.0.0+cu118 torchvision==0.15.1+cu118 torchaudio==2.0.1 --index-url https://download.pytorch.org/whl/cu118\n","- pip install ultralytics ipykernel moviepy"]},{"cell_type":"markdown","metadata":{},"source":["Check cuda"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","torch.cuda.is_available()"]},{"cell_type":"markdown","metadata":{},"source":["## Converting videos to images"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# trocando o diretório atual\n","import os\n","path = '/home/rafaa/pmy/penalty_project'\n","os.chdir(path)\n","print(os.getcwd())\n","\n","import subprocess,os,glob\n","from IPython.display import Video\n","from moviepy.editor import *\n","\n","def get_file_extension_from_filepath(filepath): return filepath.split('.')[-1]\n","def get_filename_from_filepath(filepath): return filepath.split('/')[-1].split('.')[0]\n","\n","def get_video_fps(filepath):\n","    # Get the original frame rate using ffprobe\n","    ffprobe_cmd = [\n","        \"ffprobe\",\n","        \"-v\", \"error\",\n","        \"-select_streams\", \"v:0\",\n","        \"-show_entries\", \"stream=r_frame_rate\",\n","        \"-of\", \"default=noprint_wrappers=1:nokey=1\",\n","        filepath\n","    ]\n","    # Run ffprobe to get the frame rate\n","    result = subprocess.run(ffprobe_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n","    original_fps = result.stdout.strip()\n","    return original_fps\n","\n","def convert_video_to_images(filepath, paths):\n","    filename = get_filename_from_filepath(filepath)\n","    original_fps = get_video_fps(filepath)\n","    # original_fps=60\n","    folder = f\"{paths['images']}/{filename}\"\n","    os.makedirs(folder,exist_ok=True)\n","    output_image_pattern = f\"{folder}/{filename}_%04d.jpg\"  # Adjust output pattern as needed\n","\n","    # Define FFmpeg command to convert MXF to images\n","    ffmpeg_cmd = [\n","        \"ffmpeg\",\n","        \"-y\",               # Automatically overwrite output files\n","        \"-i\", filepath,\n","        \"-vf\", f\"fps={original_fps}\",  # Set output frame rate\n","        '-q:v', '0',             # Output quality (0 - 31, 2 is a good default)\n","        '-qmin', '1',            # Minimum quantization value\n","        '-qmax', '31',           # Maximum quantization value\n","        output_image_pattern\n","    ]\n","\n","    subprocess.run(ffmpeg_cmd, check=True)\n","    print(\"Conversion complete\")\n","\n","# set folders and create them if needed\n","data_path =  f'data'\n","paths = {\n","    'videos':f'{data_path}/videos',\n","    'images':f'{data_path}/images',\n","    }\n","for p in paths.values(): os.makedirs(p,exist_ok=True)\n","\n","## get videos from path\n","# videos = glob.glob(f\"{paths['videos']}/*\")\n","# videos_processed =  ['data/videos/rf0.mp4']\n","# videos_to_process = [v for v in videos if v not in videos_processed]\n","\n","# set videos\n","videos_to_process = ['data/videos/rf0.mp4']\n","\n","for video in videos_to_process:\n","    print(video, get_video_fps(video))\n","#     convert_video_to_images(video, paths)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["videos"]},{"cell_type":"markdown","metadata":{},"source":["### Utils cli to split the data between datasets\n"," \n","```\n","# count files\n","folder = 'lf13'\n","!find \"/home/rafaa/pmy/penalty_project/data/images/$folder/no\" -type f | wc -l\n","!find \"/home/rafaa/pmy/penalty_project/data/images/$folder/yes\" -type f | wc -l\n","\n","# move files\n","datasets_folders = {\n","    'train':['lf4', 'lf5', 'lf6', 'lf7', 'lf8', 'lf9', 'lf10', 'lf11'],\n","    'valid':['lf12'],\n","    'test': ['lf13']}\n","for dataset,folders in datasets_folders.items():\n","    for folder in folders:\n","        !echo $dataset and $folder\n","        # !mv data/images/$folder/no/* data/dataset/train/no/\n","        # !mv data/images/$folder/yes/* data/dataset/train/yes/\n","        # !rm -r data/images/$folder\n","```"]},{"cell_type":"markdown","metadata":{},"source":["## Plotting frames from a video"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nXk0HM7mXPC4"},"outputs":[],"source":["import cv2 as cv\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","DEBUG = 1\n","video='data/videos/lf13.mp4'\n","cap = cv.VideoCapture(video)\n","\n","# Check if the video file is opened successfully\n","if not cap.isOpened(): \n","    print(\"Error: Could not open video file.\")\n","    # return\n","    print('error') \n","\n","# Get the video codec and properties from the input video \n","fps = int(cap.get(cv.CAP_PROP_FPS))\n","width = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n","frame_count = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n","\n","total_duration = frame_count / fps \n","print(f\"Video (sec): {0}-{round(total_duration,2)}\")\n","print(f\"Frames: {0}-{frame_count}\")\n","\n","q=0\n","frame_number=0\n","q_max = 5\n","cap.set(cv.CAP_PROP_POS_FRAMES, frame_number)\n","while(True):\n","    ret, frame = cap.read()\n","    if not ret:\n","        print(f\"Error reading frame {frame_number}\")\n","        break\n","    \n","    # Get the timestamp (time in ms) of the frame\n","    frame_time = int(cap.get(cv.CAP_PROP_POS_MSEC))\n","\n","    # plot the predicted image\n","    im = Image.fromarray(frame[..., ::-1])  # RGB PIL image\n","        \n","    # show img\n","    plt.imshow(im)\n","    plt.title(f\"Frame {frame_number} - {round(frame_time,5)} ms\")\n","    plt.axis('off')\n","    plt.show()\n","        \n","    if(q == q_max): break\n","    frame_number+=1\n","    q+=1\n","\n","cap.release()"]},{"cell_type":"markdown","metadata":{},"source":["## Plotting 1 frame"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import cv2 as cv\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","DEBUG = 1\n","cap = cv.VideoCapture(video)\n","\n","if not cap.isOpened(): \n","    print(\"Error: Could not open video file.\")\n","    print('error') \n","\n","# Get the video codec and properties from the input video \n","fps = int(cap.get(cv.CAP_PROP_FPS))\n","width = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n","frame_count = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n","\n","total_duration = frame_count / fps \n","print(f\"Video (sec): {0}-{round(total_duration,2)}\")\n","print(f\"Frames: {0}-{frame_count}\")\n","\n","frame_number=10\n","cap.set(cv.CAP_PROP_POS_FRAMES, frame_number)\n","ret, frame = cap.read()\n","plt.axis('off')\n","plt.imshow(im)\n","\n","# while(True):\n","#     ret, frame = cap.read()\n","#     if not ret:\n","#         print(f\"Error reading frame {frame_number}\")\n","#         break\n","    \n","#     # Get the timestamp (time in ms) of the frame\n","#     frame_time = int(cap.get(cv.CAP_PROP_POS_MSEC))\n","\n","#     # plot the predicted image\n","#     im = Image.fromarray(frame[..., ::-1])  # RGB PIL image\n","#     plt.imshow(im)\n","#     plt.title(f\"Frame {frame_number} - {round(frame_time,5)} ms\")\n","#     plt.axis('off')\n","#     plt.show()\n","        \n","#     if(DEBUG & (frame_number == 5)): break\n","#     frame_number+=1\n","\n","cap.release()"]},{"cell_type":"markdown","metadata":{},"source":["## Treinando o modelo YOLO V8\n","editar o arquivo de configurações, de acordo com os valores abaixo:\n","```\n","# /home/rafaa/.config/Ultralytics/settings.yaml\n","datasets_dir: /home/rafaa/pmy/penalty_project/data\n","weights_dir: /home/rafaa/pmy/penalty_project/data/weights\n","runs_dir: /home/rafaa/pmy/penalty_project/data/runs\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["os.getcwd()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from IPython.display import display\n","from PIL import Image\n","from ultralytics import YOLO\n","import os\n","\n","# change current folder\n","print(os.getcwd())\n","if 'data' not in os.getcwd():\n","    # os.makedirs('data/dataset',exist_ok=True) # criar diretorio\n","    os.chdir('data')\n","print(os.getcwd())"]},{"cell_type":"markdown","metadata":{},"source":["Realizando o treinamento com GPU"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = YOLO('yolov8n-cls.pt')\n","results = model.train(\n","    data='dataset',\n","    epochs=100,\n","    imgsz=640,\n","    verbose=True,\n","    device=0)"]},{"cell_type":"markdown","metadata":{},"source":["# Inferindo"]},{"cell_type":"markdown","metadata":{},"source":["## Imagem"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from IPython.display import display\n","from PIL import Image\n","from ultralytics import YOLO\n","import os\n","\n","# change current folder\n","os.chdir('/home/rafaa/pmy/penalty_project/data')\n","best_model_path = '/home/rafaa/pmy/penalty_project/data/dataset/runs/classify/train2/weights/best.pt'\n","path = \"/home/rafaa/pmy/penalty_project/data/images/lf13/lf13_0001.jpg\"\n","\n","# Load the model\n","model = YOLO(best_model_path)\n","\n","# inference\n","r = model(path,save=False, conf=0.15, iou=0.1,device='0')[0]\n","\n","# Show the results\n","im_array = r.plot(conf=True)  # plot a BGR numpy array of predictions\n","im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n","display(im)\n","\n","# Tratando o resultado\n","classes_names = r.names\n","probs = r.cpu().probs.data.tolist()\n","classes_probs = {}\n","for k,v in classes_names.items(): classes_probs[v] = round(probs[k],2)\n","print(\"Results : \", classes_probs)\n"]},{"cell_type":"markdown","metadata":{},"source":["## frames de um Video"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from IPython.display import display\n","from PIL import Image\n","from ultralytics import YOLO\n","import os\n","import cv2 as cv\n","import matplotlib.pyplot as plt\n","\n","# paths\n","path,frame_start,frame_end = 'videos/lf13.mp4',0,43 # test \n","# path,frame_start,frame_end = 'videos/IMG_5358.mp4',44,50 # valid\n","output_path_not_formatted = path\\\n","    .replace('videos','outputs')\\\n","    .replace('.mp4','_output_not_formatted.mp4')\n","output_path = output_path_not_formatted\\\n","    .replace('_output_not_formatted.mp4','_output.mp4')\n","\n","# change current folder\n","os.chdir('/home/rafaa/pmy/penalty_project/data')\n","best_model_path = 'dataset/runs/classify/train/weights/best.pt' # v1\n","# best_model_path = 'dataset/runs/classify/train2/weights/best.pt' # v2\n","\n","# Load the model\n","model = YOLO(best_model_path)\n","DEBUG = 0\n","count = 0\n","cap = cv.VideoCapture(path)\n","\n","# Check if the video file is opened successfully\n","if not cap.isOpened(): \n","    print(\"Error: Could not open video file.\")\n","    # return\n","    print('error') \n","\n","# Get the video codec and properties from the input video \n","fps = int(cap.get(cv.CAP_PROP_FPS))\n","width = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n","frame_count = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n","total_duration = frame_count / fps \n","print(f\"Video (sec): {0}-{round(total_duration,2)}\")\n","print(f\"Frames: {0}-{frame_count}\")\n","\n","# Write output video\n","fourcc = cv.VideoWriter_fourcc(*'mp4v')\n","out = cv.VideoWriter(output_path_not_formatted, fourcc, fps, (width, height))\n","\n","frame_number=0\n","cap.set(cv.CAP_PROP_POS_FRAMES, frame_number)\n","while(True):\n","    ret, frame = cap.read()\n","    if not ret:\n","        print(f\"Error reading frame {frame_number}\")\n","        break\n","\n","    frame_ = frame.copy()\n","    # Get the timestamp (time in ms) of the frame\n","    frame_time = int(cap.get(cv.CAP_PROP_POS_MSEC))\n","    frame_number+=1\n","\n","    if (frame_number < frame_start or frame_number > frame_end) : continue\n","\n","    count+=1\n","    # inference\n","    r = model(frame,save=False, conf=0.01, iou=0.1,device='0',verbose=False)[0]\n","\n","    classes_names = r.names\n","    probs = r.cpu().probs.data.tolist()\n","    classes_probs = {}\n","    for k,v in classes_names.items(): classes_probs[v] = round(probs[k],2)\n","\n","    # Define the position and size of the rectangle\n","    top_left_corner = (0, 0)\n","    bottom_right_corner = (width, 100)\n","    rectangle_color = (255, 255, 255)  # White color in BGR\n","    rectangle_thickness = -1  # Filled rectangle\n","\n","    # Draw the white rectangle\n","    cv.rectangle(frame, top_left_corner, bottom_right_corner, rectangle_color, rectangle_thickness)\n","\n","    # Write text on the frame using OpenCV before converting it to RGB\n","    font = cv.FONT_HERSHEY_SIMPLEX\n","    classes_probs_text = f\"No ({classes_probs['no']*100.0}%) - Yes ({classes_probs['yes']*100.0}%)\" \n","    text = f\"Frame {frame_number}/{frame_count} - Time {round(frame_time,5)} ms - {classes_probs_text}\"\n","    position = (50, 70)\n","    font_scale = 1.5\n","    font_color = (0, 0, 0)\n","    line_type = 2\n","\n","    # Calculate text size\n","    (text_width, text_height), _ = cv.getTextSize(text, font, font_scale, line_type)\n","\n","    # Calculate the center position\n","    text_x = (width - text_width) // 2\n","    text_y = top_left_corner[1] + ((bottom_right_corner[1] - top_left_corner[1]) + text_height) // 2\n","\n","    # The position where the text will start\n","    position = (text_x, text_y)\n","\n","    # Put the text on the frame\n","    cv.putText(frame, text, position, font, font_scale, font_color, line_type)\n","    frame_rgb = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n","\n","    # # save image\n","    # cv.imwrite(f'{frame_number}.jpg', frame)\n","\n","    # # plot frame\n","    # plt.figure(figsize=(10, 5))\n","    # plt.imshow(frame_rgb)\n","    # plt.axis('off')\n","    # plt.show()\n","    \n","    out.write(frame)\n","\n","    if(DEBUG == 1 and count == 1): break\n","\n","cap.release()\n","out.release()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!ffmpeg -y -i $output_path_not_formatted -c:v libx264 -preset fast -crf 22 -c:a aac $output_path\n","! rm $output_path_not_formatted"]},{"cell_type":"markdown","metadata":{},"source":["### Editing the text in the frame output (Run previous cell with 1 or more frames first)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["frame = frame_.copy()\n","\n","# Define the position and size of the rectangle\n","top_left_corner = (0, 0)\n","bottom_right_corner = (width, 100)\n","rectangle_color = (255, 255, 255)  # White color in BGR\n","rectangle_thickness = -1  # Filled rectangle\n","\n","# Draw the white rectangle\n","cv.rectangle(frame, top_left_corner, bottom_right_corner, rectangle_color, rectangle_thickness)\n","\n","# Write text on the frame using OpenCV before converting it to RGB\n","font = cv.FONT_HERSHEY_SIMPLEX\n","classes_probs_text = f\"No ({classes_probs['no']*100.0}%) - Yes ({classes_probs['yes']*100.0}%)\" \n","text = f\"Frame {frame_number}/{frame_count} - Time {round(frame_time,5)} ms - {classes_probs_text}\"\n","position = (50, 70)\n","font_scale = 1.5\n","font_color = (0, 0, 0)\n","line_type = 2\n","\n","# Calculate text size\n","(text_width, text_height), _ = cv.getTextSize(text, font, font_scale, line_type)\n","\n","# Calculate the center position\n","text_x = (width - text_width) // 2\n","text_y = top_left_corner[1] + ((bottom_right_corner[1] - top_left_corner[1]) + text_height) // 2\n","\n","# The position where the text will start\n","position = (text_x, text_y)\n","\n","# Put the text on the frame\n","cv.putText(frame, text, position, font, font_scale, font_color, line_type)\n","frame_rgb = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n","\n","cv.imwrite('image.png', frame)\n","\n","plt.imshow(frame_rgb)\n","plt.axis('off')\n","plt.show()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNkiQIMcb9KkK/Pmmxlu4GX","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
